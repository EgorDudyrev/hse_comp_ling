{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Срок выполнения задания – до 5 апреля включительно.\n",
    "\n",
    "Отчет высылается по почте Зуеву Кириллу на адрес  kir2207@list.ru\n",
    "\n",
    "В качестве темы письма указать:  «КЛ ДЗ № 3, ФИО»\n",
    "\n",
    "Отчет должен быть в виде отдельного текста, код программы включается как приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание E.\n",
    "Составить (с использованием любого модуля морфоанализа) программу, выполняющую извлечение словосочетаний определенного вида из заданного русскоязычного текста. Выделение словосочетаний может базироваться на локальных высоковероятных синтаксических связях (см. слайд 50 Лекции  № 7). Программа выводит все словосочетания  заданного вида/ов, встречающиеся в обрабатываемом тексте. \n",
    "Рассмотреть несколько (2-5) грамматических образцов словосочетаний, например:\n",
    "* именные словосочетания (NP), в которые входят  грамматически согласованные прилагательные и существительное (и, возможно, порядковые числительные или наречие,  например: первый детальный написанный план или более сложный образец: первый детально написанный план);\n",
    "* именные словосочетания, включающие несколько существительных и прилагательные (зависимые существительные входят в родительном падеже, прилагательные согласованы с соответствующими существительными, например: легкий отблеск далекого заката);\n",
    "* предложные словосочетания, в которые входят именные словосочетания одного из грамматических образцов (например: в тихом летнем парке);\n",
    "* глагольные группы, состоящие из глагола в личной форме  и зависимой именной группы (например: увидел большой стеклянный шар).\n",
    "\n",
    "Протестировать программу на нескольких небольших текстах разных жанров.\n",
    "\n",
    "Отчет:  Описание грамматических образцов извлекаемых словосочетаний и стратегии (алгоритма) их выделения; составленная и примененная программа с комментариями, результаты ее тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выкачиваем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Художественный текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR+'art_alice_full_text.txt', 'r') as f:\n",
    "    alice_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_txt_by_chapter = {idx:s.strip() for idx, s in enumerate([s for s in re.split('Глава.*\\n\\n\\n', alice_txt) if len(s)>0])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Научно-технический текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ПОСОБИЕ ПО НАПИСАНИЮ\n",
    "РАЗНОГО РОДА ДЕЛОВЫХ ТЕКСТОВ\"\n",
    "https://www.iis.nsk.su/files/articles/sbor_kas_16_nesgovorova.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR+'doc_how_to_business_text.txt','r') as f:\n",
    "    how_to_buis_txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beautify_str(s):\n",
    "    s = re.sub(r'Рис\\. \\d+\\n+', '', s)\n",
    "    s = re.sub('[^\\.?;\\n](\\n)[^\\n]', ' ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_txt_by_chapter = {idx:beautify_str(s) for idx,s in alice_txt_by_chapter.items()}\n",
    "how_to_buis_txt = beautify_str(how_to_buis_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ищем статистику с pymorphy и считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/egor/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    }
   ],
   "source": [
    "mstm = mystem.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_dicts = pd.read_html('https://yandex.ru/dev/mystem/doc/grammemes-values-docpage/')\n",
    "mystem_dicts = mystem_dicts[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_dicts_d = {k:mystem_dicts[idx] for idx, k in enumerate([\n",
    "    'POS','Tense','Case','Number','Mood',\n",
    "    'Fullness','Suprs','Person', 'Gender', 'Aspect',\n",
    "    'Voice','Animacy', 'Transitivity','Other'\n",
    "])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_semisentences(txt):\n",
    "    #return [x.strip(' ').strip('\\n').strip('\\t') for x in re.sub(r'[^\\w\\s\\'\\`]','|', txt).split('|') if x.strip(' ').strip('\\n')!='']\n",
    "    return [x.strip() for x in re.sub(r'[^\\w\\s\\'\\`]','|', txt).split('|') if x.strip()!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_word(txt):\n",
    "    return [x.strip() for x in re.split(' ', txt) if re.match('\\w', x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_lexeme(w):\n",
    "    p = morph.parse(w)[0]\n",
    "    t = p.tag\n",
    "    lxm = {'word':p.word, 'POS': t.POS}    \n",
    "    lxm['animacy'] = t.animacy       # одушевленность\n",
    "    lxm['aspect'] = t.aspect        # вид: совершенный или несовершенный\n",
    "    lxm['case'] = t.case          # падеж\n",
    "    lxm['gender'] = t.gender        # род (мужской, женский, средний)\n",
    "    lxm['involvment'] = t.involvement   # включенность говорящего в действие\n",
    "    lxm['mood'] = t.mood          # наклонение (повелительное, изъявительное)\n",
    "    lxm['number'] = t.number        # число (единственное, множественное)\n",
    "    lxm['person'] = t.person        # лицо (1, 2, 3)\n",
    "    lxm['tense'] = t.tense         # время (настоящее, прошедшее, будущее)\n",
    "    lxm['transitivity'] = t.transitivity  # переходность (переходный, непереходный)\n",
    "    lxm['voice'] = t.voice  \n",
    "    \n",
    "    lxm = {k:v for k,v in lxm.items() if v is not None}\n",
    "    return lxm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Алисе наскучило сидеть с сестрой без дела на берегу реки'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = split_by_semisentences(alice_txt_by_chapter[0])[0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'хоть сейчас был не самый подходящий момент демонстрировать свои познания'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lexemes = [construct_lexeme(w) for w in split_by_word(txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_lexemes_mystem(txt):\n",
    "    lexemes = mstm.analyze(txt)\n",
    "    lexemes = [lxm for lxm in lexemes if lxm['text'].strip()!='']\n",
    "    \n",
    "    new_lexemes = []\n",
    "    for lxm in lexemes:\n",
    "        anl = lxm['analysis']\n",
    "        if len(anl)>1:\n",
    "            print(f'More then 1 analysis for lexeme {lxm}')\n",
    "        gr = anl[0]['gr']\n",
    "        \n",
    "        gr_const, gr_var = gr.split('=')[0], gr.split('=')[1].replace('(','').replace(')','')\n",
    "        variants = [set(gr_const.split(',')+x.split(',')) for x in gr_var.split('|')] if gr_var!='' else [set(gr_const.split(','))]\n",
    "        \n",
    "        parsed_vars = []\n",
    "        for var in variants:\n",
    "            parsed_var = {}\n",
    "            for x in var:\n",
    "                for k,v in mystem_dicts_d.items():\n",
    "                    if x in v[0].values:\n",
    "                        parsed_var[k]=x\n",
    "                        break\n",
    "            parsed_var['mystem_view'] = var\n",
    "            parsed_var['word'] = lxm['text']\n",
    "            parsed_vars.append(parsed_var)\n",
    "        new_lexemes.append(parsed_vars)\n",
    "    \n",
    "    return new_lexemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск грамматических образцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "Именные словосочетания (NP), в которые входят  грамматически согласованные прилагательные и существительное (и, возможно, порядковые числительные или наречие,  например: первый детальный написанный план или более сложный образец: первый детально написанный план);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'POS': 'ADV', 'mystem_view': {'ADV'}, 'word': 'более'}]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_quaziadj_noun_agree(adj, n):\n",
    "    for var_adj in adj:\n",
    "        for var_n in n:\n",
    "            if var_adj['POS']=='ADV' and var_n['POS']=='S':\n",
    "                return True\n",
    "            \n",
    "            if ((var_adj['POS'] in ['A','ANUM','APRO']) or (var_adj.get('POS')=='V' and var_adj.get('Mood')=='прич')) and \\\n",
    "                (var_n['POS']=='S') and \\\n",
    "                (var_adj['POS'] in ['APRO'] or ('Gender' in var_n and var_adj.get('Gender')==var_n.get('Gender'))) and \\\n",
    "                (var_n['Number']=='мн' or (var_adj.get('Number')==var_n.get('Number'))) and \\\n",
    "                ('Case' in var_n and var_adj.get('Case')==var_n.get('Case')) \\\n",
    "            : \n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NP1(lexemes):\n",
    "    groups = []\n",
    "    nouns = [idx for idx, lxm in enumerate(lexemes) if idx>0 and any([var['POS']=='S' for var in lxm])]\n",
    "    for noun_idx in nouns:\n",
    "        noun = lexemes[noun_idx]\n",
    "        first_adj_idx = noun_idx\n",
    "        while True:\n",
    "            new_first_adj_idx = first_adj_idx-1\n",
    "            if first_adj_idx<0:\n",
    "                break\n",
    "\n",
    "            new_first_adj = lexemes[new_first_adj_idx]\n",
    "\n",
    "            if is_quaziadj_noun_agree(new_first_adj, noun): # число род падеж\n",
    "                first_adj_idx -= 1\n",
    "            else:\n",
    "                break\n",
    "        if first_adj_idx==noun_idx:\n",
    "            continue\n",
    "\n",
    "        groups.append(f' '.join([x[0]['word'] for x in lexemes[first_adj_idx:noun_idx+1]]))\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'хоть сейчас был не самый подходящий момент демонстрировать свои познания'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#txt = 'первый детальный написанный план'\n",
    "#txt = 'более сложный образец'\n",
    "txt = 'первый детально написанный план'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#idx = 10\n",
    "idx -= 1\n",
    "txt = split_by_semisentences(alice_txt_by_chapter[0])[idx]\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexemes = construct_lexemes_mystem(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['самый подходящий момент', 'свои познания']"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_NP1(lexemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
