{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/egor/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.abspath('../../bert_uncased_L-12_H-768_A-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_config.json\t\t     bert_model.ckpt.index\r\n",
      "bert_model.ckpt.data-00000-of-00001  vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls {MODEL_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FROM https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"\n",
    "\n",
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = encoded_layers[-1][0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.28727067e-02, -2.34608755e-01, -7.99242482e-02,  3.89052689e-01,\n",
       "        8.87931108e-01,  2.13749602e-01, -7.80640822e-03,  6.26940608e-01,\n",
       "       -3.26306000e-02, -3.47033143e-01,  1.23310499e-01, -9.47718173e-02,\n",
       "       -7.44204372e-02,  4.55233961e-01, -4.72169489e-01,  1.03437662e-01,\n",
       "        3.46665353e-01,  1.04095027e-01,  5.43724000e-01,  6.91130012e-02,\n",
       "       -8.28798041e-02,  6.78661689e-02,  1.28705993e-01,  2.33115733e-01,\n",
       "        4.29326892e-01, -1.24495002e-02, -2.13598713e-01,  2.26974905e-01,\n",
       "       -1.27629027e-01,  2.80796528e-01,  5.47655642e-01, -1.00796588e-01,\n",
       "        7.56504387e-02, -2.71524072e-01, -1.41239136e-01, -4.09305930e-01,\n",
       "       -1.92370981e-01, -3.98125611e-02, -2.31750205e-01,  3.30400884e-01,\n",
       "       -3.84840667e-01, -3.74688238e-01, -2.49777943e-01,  3.27066422e-01,\n",
       "       -9.05585533e-04, -4.42851841e-01,  7.68331885e-02, -4.46174890e-02,\n",
       "        1.98076665e-02,  7.46791884e-02, -3.29857558e-01,  8.21141005e-01,\n",
       "       -7.62564719e-01, -4.16213821e-04,  8.90901089e-02,  5.34717858e-01,\n",
       "       -3.82436752e-01, -6.01839185e-01, -8.39414671e-02, -9.60097536e-02,\n",
       "        3.76894385e-01, -2.52872676e-01,  4.64288920e-01, -5.47606647e-01,\n",
       "       -2.12299842e-02,  2.08275225e-02,  4.81912971e-01,  2.80349195e-01,\n",
       "       -3.25332195e-01,  3.02193929e-02, -4.03405011e-01,  1.96262732e-01,\n",
       "       -2.19119087e-01, -3.66373539e-01,  6.27375580e-03,  4.73302841e-01,\n",
       "       -8.04091990e-02, -2.98622027e-02, -2.93532044e-01,  2.11905390e-01,\n",
       "       -2.06036657e-01,  3.94703031e-01, -1.41665801e-01,  2.42766008e-01,\n",
       "        1.45296901e-01,  5.11234142e-02, -1.87403187e-01,  7.70086125e-02,\n",
       "       -3.38804461e-02,  4.47654843e-01, -5.56954741e-02,  1.39572755e-01,\n",
       "       -1.98343262e-01, -3.49337459e-02, -4.21849728e-01,  2.19982922e-01,\n",
       "        1.43549675e-02,  9.01020095e-02, -2.76118726e-01,  4.62191075e-01,\n",
       "        1.03267170e-01, -5.54646075e-01,  2.54117996e-01,  4.01434064e-01,\n",
       "       -2.37608096e-03, -1.07146986e-02,  3.42063785e-01,  6.86753541e-02,\n",
       "       -2.12056816e-01, -9.59718153e-02,  1.27283692e-01, -2.88845509e-01,\n",
       "        2.19588429e-01, -2.64260381e-01,  2.98485160e-02, -1.01088721e-03,\n",
       "        4.37536329e-01, -3.01790833e-01, -5.32501817e-01, -1.14063978e-01,\n",
       "        4.08741385e-01,  2.41679370e-01,  3.44927639e-01,  8.73415768e-01,\n",
       "       -2.40147635e-01,  2.17793241e-01,  2.83730924e-02,  1.67827606e-01,\n",
       "       -1.39829174e-01, -6.20042384e-01,  3.99549663e-01,  2.88693905e-02,\n",
       "        1.75431907e-01, -1.84153512e-01, -2.56429404e-01,  2.23220065e-01,\n",
       "       -1.16520613e-01, -2.49547914e-01, -5.38879037e-01,  2.56147802e-01,\n",
       "        3.03055316e-01, -3.53549689e-01, -8.11939538e-02,  2.93234766e-01,\n",
       "        6.47438243e-02,  3.96046251e-01,  2.68050730e-01, -2.71992505e-01,\n",
       "        1.90488711e-01,  2.20431045e-01,  2.65806943e-01,  1.79436162e-01,\n",
       "       -1.34112075e-01, -2.69646853e-01,  3.57325584e-01,  2.24899590e-01,\n",
       "        1.32773845e-02,  4.04935703e-02, -1.30249575e-01, -1.33644953e-01,\n",
       "        3.20342630e-01,  2.61174142e-01, -3.47047120e-01,  1.76685423e-01,\n",
       "       -2.53802359e-01,  3.04912217e-02,  2.41845742e-01,  2.41482079e-01,\n",
       "       -2.83401757e-01,  7.36021847e-02, -3.12893867e-01,  4.54278961e-02,\n",
       "        5.65936685e-01, -6.41364157e-02,  1.35577902e-01,  1.18511058e-01,\n",
       "       -2.35384166e-01, -1.32175103e-01,  1.91831604e-01, -1.35998890e-01,\n",
       "       -1.14939678e+00,  3.65844339e-01,  3.11234176e-01,  2.80612797e-01,\n",
       "        2.39547595e-01, -2.49463409e-01,  3.01228970e-01,  9.95714217e-02,\n",
       "       -2.37400725e-01, -4.49246585e-01,  5.26367091e-02, -5.14813960e-01,\n",
       "       -6.59891129e-01,  1.17187470e-01, -6.32728264e-02, -1.14234924e-01,\n",
       "       -2.68334508e-01, -1.91820916e-02, -2.40277901e-01, -4.43728603e-02,\n",
       "       -1.75688803e-01, -3.17604169e-02,  7.91369751e-02,  7.16947243e-02,\n",
       "       -6.75856397e-02,  8.78373627e-03,  2.05915540e-01,  2.19705403e-02,\n",
       "        3.68093282e-01,  2.04498678e-01, -2.82408565e-01,  2.87366688e-01,\n",
       "        2.38959461e-01,  3.50025087e-03, -4.05839719e-02, -3.75267491e-02,\n",
       "       -3.18725884e-01, -4.45328981e-01, -1.88295897e-02,  8.74798819e-02,\n",
       "        3.93580645e-02,  2.53840536e-01, -1.71771109e-01,  3.67042452e-01,\n",
       "        1.16847657e-01,  8.81507814e-01, -1.82971761e-01, -2.23819688e-01,\n",
       "       -2.51704782e-01,  2.30967700e-01, -1.84196845e-01, -1.28085136e-01,\n",
       "        2.51443267e-01, -1.35661811e-01, -2.77109712e-01, -1.72384292e-01,\n",
       "       -2.26743519e-01, -1.08936854e-01, -2.21525326e-01, -3.21504921e-01,\n",
       "        5.14380075e-02,  8.18303302e-02,  4.47616309e-01, -1.81710616e-01,\n",
       "        1.78121001e-01,  4.23917696e-02,  2.09527820e-01,  5.92372298e-01,\n",
       "       -1.51796401e-01, -2.48477593e-01, -3.63140553e-01, -2.79565930e-01,\n",
       "       -2.67628074e-01, -4.06012505e-01,  2.22210273e-01, -2.32892424e-01,\n",
       "        2.83701532e-02, -8.35644640e-03, -6.95766434e-02,  1.88514665e-01,\n",
       "        5.07099926e-01, -3.03160306e-02, -9.01766047e-02, -1.08184596e-03,\n",
       "       -2.57210940e-01, -4.34414417e-01, -1.92856699e-01,  2.40374520e-01,\n",
       "        1.58157468e-01,  2.68346369e-01,  2.30476320e-01,  1.83294728e-01,\n",
       "       -1.40227936e-02,  4.21131164e-01, -2.58150827e-02, -2.82111675e-01,\n",
       "       -4.15485166e-02,  4.72476287e-03,  4.99553904e-02, -4.20471653e-02,\n",
       "        2.49048516e-01,  5.31731367e-01, -4.29344773e-01, -3.25882703e-01,\n",
       "        1.00134589e-01, -3.63639325e-01, -9.94306505e-02,  6.26592755e-01,\n",
       "       -2.71122992e-01, -2.15656415e-01, -1.54688090e-01,  8.35501105e-02,\n",
       "       -3.61120909e-01,  9.65140387e-02, -1.73138767e-01,  2.15881646e-01,\n",
       "        1.56388268e-01,  5.93671858e-01,  6.66492820e-01, -6.75883815e-02,\n",
       "        1.50302276e-01,  1.45057470e-01,  2.53578871e-01, -3.96850742e-02,\n",
       "       -2.39347652e-01,  9.33574364e-02,  4.78129864e-01, -3.00635666e-01,\n",
       "       -3.77702236e+00,  7.75520086e-01,  4.02787983e-01, -3.50193918e-01,\n",
       "        3.89378332e-02, -1.23757787e-01, -1.10076793e-01, -4.86478239e-01,\n",
       "       -2.59333879e-01,  1.71680868e-01, -4.22790885e-01, -5.54711103e-01,\n",
       "        3.16107154e-01, -1.10996135e-01,  1.25567570e-01, -4.58634168e-01,\n",
       "        1.99560732e-01, -2.33708203e-01,  1.42275393e-01,  1.38013825e-01,\n",
       "       -1.90413415e-01, -2.01232493e-01, -2.18908846e-01,  1.76414460e-01,\n",
       "        5.50507486e-01,  4.21033353e-01, -4.99327391e-01, -1.35167778e-01,\n",
       "        2.45119467e-01,  1.22178800e-01,  1.22162886e-01, -2.24404201e-01,\n",
       "       -2.36442849e-01, -4.10469919e-01,  1.90443531e-01,  7.08859935e-02,\n",
       "       -1.66052863e-01, -1.25169426e-01, -1.09681729e-02,  1.94214195e-01,\n",
       "       -2.52210498e-01, -2.29303181e-01, -1.67553216e-01,  4.97718789e-02,\n",
       "        9.73854601e-01,  1.31266132e-01, -1.78785533e-01, -5.14915705e-01,\n",
       "        4.24420573e-02,  2.58976698e-01,  4.46940899e-01, -3.09475303e-01,\n",
       "       -2.20840320e-01,  2.92762578e-01,  9.68796536e-02, -8.77025444e-03,\n",
       "        2.02744871e-01,  3.32558453e-02, -1.41736835e-01, -4.48201522e-02,\n",
       "       -6.24461286e-02, -4.62747008e-01, -1.06911875e-01,  8.40848982e-02,\n",
       "       -9.67807975e-03, -3.48519772e-01, -3.59035552e-01, -2.26666708e-03,\n",
       "        2.32873663e-01,  8.27527791e-03,  8.39300826e-02,  3.92286003e-01,\n",
       "       -3.91680211e-01, -9.05331969e-01, -3.28196734e-01, -9.67666856e-04,\n",
       "        6.32858515e-01, -2.03399792e-01,  2.10919008e-01, -5.27219884e-02,\n",
       "       -2.52259225e-01, -1.97125256e-01,  2.26953223e-01, -1.23937555e-01,\n",
       "        2.80512646e-02, -3.88594419e-01, -1.20374247e-01,  3.01860005e-01,\n",
       "       -3.85890841e-01, -6.73368037e-01,  4.13082480e-01,  3.94673049e-01,\n",
       "        1.74029604e-01, -5.07310145e-02, -3.93945239e-02,  6.40843138e-02,\n",
       "       -2.59276271e-01, -2.08946645e-01, -6.61575655e-03,  6.73435405e-02,\n",
       "       -5.39949499e-02, -6.82308152e-02,  3.94350827e-01, -1.62283033e-01,\n",
       "       -5.91484644e-02, -1.09868653e-01, -2.34854877e-01,  6.07638136e-02,\n",
       "       -5.27078092e-01,  3.19850236e-01,  1.50071159e-01, -5.32410026e-01,\n",
       "        7.46031523e-01,  2.96251336e-03,  7.07196295e-02,  2.90056556e-01,\n",
       "        5.86967885e-01,  4.55779076e-01,  7.81978592e-02,  3.27003282e-03,\n",
       "       -2.59533167e-01,  4.73646522e-01, -4.74521816e-01, -3.19380671e-01,\n",
       "        6.36778772e-02, -1.25645027e-01,  1.04251578e-01, -1.18372589e-01,\n",
       "        8.11478123e-02, -3.17815691e-01,  8.73753875e-02, -3.95480454e-01,\n",
       "        1.20833606e-01,  8.98498371e-02,  3.75193626e-01, -1.22690499e-02,\n",
       "        2.23276377e-01, -1.12077248e+00,  6.42186031e-02,  3.65874171e-01,\n",
       "       -1.71934739e-01,  2.05675855e-01, -1.26112914e-02, -3.20889831e-01,\n",
       "       -2.57596731e-01,  1.07535154e-01,  3.65678631e-02, -6.17954955e-02,\n",
       "       -7.86595419e-02, -8.22357014e-02, -4.33499843e-01, -9.86767816e-04,\n",
       "        1.02872245e-01, -5.20390749e-01, -8.46098214e-02,  3.95575345e-01,\n",
       "        2.54037738e-01, -9.45154950e-02, -5.61938405e-01, -2.36915573e-02,\n",
       "        9.72435996e-02,  2.25186870e-01,  3.91281039e-01,  3.58181298e-02,\n",
       "       -9.87543881e-01,  2.22429097e-01, -4.99789238e-01, -2.78772563e-01,\n",
       "       -2.22559229e-01,  7.10304618e-01,  5.68137281e-02, -2.41258517e-01,\n",
       "        4.53158282e-02,  9.86882225e-02,  7.26376334e-03,  3.46533686e-01,\n",
       "        2.51130704e-02, -2.67365247e-01, -2.03658864e-01,  4.36378233e-02,\n",
       "       -3.67449760e-01,  2.36965001e-01, -2.55551696e-01, -2.94466883e-01,\n",
       "        3.20455253e-01, -4.09404747e-02, -2.47629602e-02,  8.69677961e-02,\n",
       "        5.13393171e-02, -1.84112650e-04, -1.48927011e-02,  3.25257331e-01,\n",
       "       -3.82685438e-02,  2.67857909e-01, -3.56564999e-01, -4.56949800e-01,\n",
       "        1.37291759e-01,  1.44376650e-01,  2.35234983e-02,  3.80443364e-01,\n",
       "        1.57850161e-01,  1.70758087e-02, -1.74189612e-01, -9.58485082e-02,\n",
       "       -1.57672077e-01, -3.85917544e-01,  3.03183824e-01,  1.58752799e-01,\n",
       "       -3.86087984e-01,  4.44042504e-01, -2.92442530e-01,  2.02308558e-02,\n",
       "       -6.40935600e-01, -5.74478745e-01,  1.59952700e-01,  2.77254693e-02,\n",
       "        4.69581157e-01,  1.29750222e-01, -2.87808716e-01, -1.37742400e-01,\n",
       "       -3.70006770e-01,  1.53150475e-02,  1.51055038e-01,  4.92272861e-02,\n",
       "       -6.14775360e-01, -2.28199199e-01,  1.94034815e-01,  2.32945204e-01,\n",
       "        3.18161361e-02,  3.61595415e-02, -2.05998868e-02, -1.50402104e-02,\n",
       "       -1.80704609e-01,  2.52120495e-01,  3.35674733e-01,  1.76053450e-01,\n",
       "       -1.77634761e-01, -6.60030901e-01, -1.59659550e-01, -7.57845938e-02,\n",
       "       -9.27485749e-02,  4.11934376e-01, -1.47007838e-01,  1.80707514e-01,\n",
       "        2.77269632e-01,  2.28856042e-01,  2.14124486e-01,  4.05591935e-01,\n",
       "        2.94878837e-02,  1.59389555e-01,  8.94844458e-02,  1.78190898e-02,\n",
       "        1.25776887e-01,  2.14155689e-01, -6.37312829e-01, -1.34923995e-01,\n",
       "       -3.49148005e-01,  3.64783332e-02, -1.44198298e-01,  2.24439606e-01,\n",
       "        8.06177184e-02, -4.59482372e-01, -2.55479485e-01,  2.33081803e-01,\n",
       "        4.83164787e-01, -4.83029447e-02,  1.37327686e-01,  3.84481788e-01,\n",
       "        1.98586717e-01, -1.15882568e-01,  1.94618508e-01, -5.71367741e-01,\n",
       "       -2.18045767e-02,  1.81184914e-02, -1.86477423e-01,  3.25689226e-01,\n",
       "       -3.13997567e-02, -7.48517454e-01, -2.81364709e-01, -4.13455606e-01,\n",
       "       -4.32984233e-01,  8.88527334e-02,  8.01226646e-02, -9.63562950e-02,\n",
       "       -1.02895431e-01, -6.70892298e-02, -1.81349441e-02,  3.89825732e-01,\n",
       "       -2.24195436e-01, -6.57815635e-01,  1.67138159e-01,  1.66465998e-01,\n",
       "        2.27867275e-01, -9.89127904e-02, -4.99806553e-02,  2.40466684e-01,\n",
       "        5.14641643e-01,  3.04148376e-01,  1.95029110e-01,  3.90657246e-01,\n",
       "       -7.74271488e-02,  2.13993490e-01, -4.99906093e-02,  3.74014646e-01,\n",
       "       -1.31708294e-01,  2.51061291e-01, -1.93015337e-01, -2.33729973e-01,\n",
       "       -1.25523224e-01,  9.86666381e-02, -2.56773114e-01, -6.04506850e-01,\n",
       "        2.71877199e-01,  5.87892756e-02, -4.77283269e-01, -2.48089597e-01,\n",
       "        1.06370613e-01, -2.44080976e-01, -6.83126390e-01,  1.55429751e-01,\n",
       "       -3.84796150e-02, -1.09987520e-01,  2.46123925e-01,  3.17016244e-01,\n",
       "        1.50084630e-01,  4.76027042e-01, -2.13301137e-01,  2.59033795e-02,\n",
       "       -4.41346653e-02,  1.88073501e-01, -3.22095484e-01,  5.71682788e-02,\n",
       "       -2.69960284e-01,  2.17159808e-01, -2.06769183e-01, -1.49302021e-01,\n",
       "        6.64740503e-02, -3.59946609e-01,  2.75748312e-01, -3.39632303e-01,\n",
       "        1.32090583e-01, -1.00431941e-01, -2.84235310e-02,  8.86326373e-01,\n",
       "        2.60620743e-01, -1.07975891e-02, -1.29115984e-01, -2.66262181e-02,\n",
       "        4.14783388e-01,  3.07181478e-01,  6.07085116e-02,  9.17069688e-02,\n",
       "       -4.08166610e-02, -5.03894985e-01,  6.97807729e-01,  2.52770364e-01,\n",
       "        2.08319038e-01, -7.79271126e-02, -2.74229139e-01,  3.07593167e-01,\n",
       "        1.43929094e-01, -1.94459438e-01,  4.06815886e-01, -5.26208937e-01,\n",
       "       -1.81635380e-01,  1.49279654e-01, -4.02628601e-01, -3.98285359e-01,\n",
       "       -8.18808749e-02, -2.22256538e-02,  3.04048002e-01,  2.86184579e-01,\n",
       "       -2.42120221e-01, -4.51296508e-01, -9.49544162e-02,  4.18231010e-01,\n",
       "       -1.76055938e-01,  2.22152576e-01,  2.78815404e-02, -1.75528273e-01,\n",
       "        3.02799715e-04, -2.46257678e-01, -4.17561531e-01, -5.09235203e-01,\n",
       "       -3.44436139e-01, -1.34228364e-01, -2.62891110e-02, -1.05846792e-01,\n",
       "       -1.22185186e-01, -5.49477816e-01,  4.25559312e-01, -3.30323189e-01,\n",
       "        1.83970556e-01, -2.34580804e-02,  1.30041674e-01, -4.79275018e-01,\n",
       "        1.80011153e-01,  5.12052000e-01,  4.06204253e-01, -4.97024097e-02,\n",
       "        1.59075081e-01, -3.38488936e-01, -1.82568207e-02,  5.77748101e-03,\n",
       "       -3.44938338e-01, -5.15030045e-03,  1.35204241e-01, -2.24865787e-02,\n",
       "       -5.25737524e-01,  4.49999243e-01,  9.10790041e-02, -7.81267434e-02,\n",
       "       -8.13743055e-01,  3.78773957e-01, -1.31572038e-02, -5.42550832e-02,\n",
       "        2.09714323e-01,  4.85708743e-01, -1.99172154e-01,  2.12737575e-01,\n",
       "       -1.18914088e-02, -6.41852543e-02, -1.09407090e-01,  1.44958034e-01,\n",
       "       -4.94731456e-01,  4.16077882e-01,  4.23091166e-02,  5.62785305e-02,\n",
       "        5.79713471e-02,  7.46342689e-02, -1.02948189e-01,  3.84890884e-02,\n",
       "        4.55588736e-02,  2.20238075e-01, -1.44700408e-01, -3.00523162e-01,\n",
       "       -2.75542706e-01,  5.35158217e-01, -2.63285905e-01,  1.93912998e-01,\n",
       "        4.31210518e-01,  1.27498126e-02,  2.49776363e-01,  8.11297148e-02,\n",
       "        1.18376859e-01, -4.87548746e-02, -4.55448061e-01, -1.76527172e-01,\n",
       "        2.36183301e-01, -2.37896532e-01, -1.90364271e-01,  1.87623743e-02,\n",
       "       -1.21240407e-01, -4.19495493e-01, -2.48846471e-01, -1.04007296e-01,\n",
       "        3.05785000e-01, -1.83700174e-01, -8.98542702e-02,  3.83677855e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, tokenizer, model):\n",
    "    # Add the special tokens.\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)[:511]\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    \n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "    embed = np.array(encoded_layers[-1][0].mean(0))\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = get_embedding('How are you?', tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed1 = get_embedding('How you are?', tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8f357f66a0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(embed-embed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8f35800898>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(embed)\n",
    "sns.distplot(embed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.abspath('../../data/stanfordSentimentTreebank/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_split = pd.read_csv(DATA_DIR+'/datasetSplit.txt').set_index('sentence_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sent_labels = pd.read_csv(DATA_DIR+'/sentiment_labels.txt', sep='|').set_index('phrase ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sents = pd.read_csv(DATA_DIR+'/datasetSentences.txt', sep='\\t').set_index('sentence_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50401cff03af4e4d9429e0541eb29f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11855.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "for s in tqdm(ds_sents['sentence'].values):\n",
    "    embeds.append(get_embedding(s, tokenizer, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.index = ds_sents.index[:len(ds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv(DATA_DIR+'/sent_bert_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(DATA_DIR+'/sent_bert_embeddings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11855, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8544\n",
       "2    2210\n",
       "3    1101\n",
       "Name: splitset_label, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_split['splitset_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds[ds_split['splitset_label']==1]\n",
    "test_ds = ds[ds_split['splitset_label']==2]\n",
    "val_ds = ds[ds_split['splitset_label']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 84.1MB [06:58, 201kB/s]                               \n"
     ]
    }
   ],
   "source": [
    "from torchnlp.datasets import imdb_dataset\n",
    "\n",
    "# Load the imdb training dataset\n",
    "train, test = imdb_dataset(train=True, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.DataFrame(train)\n",
    "test_ds = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Since Educating Rita, Julie Walters has been o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is one of the best movies out there and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Dumland focuses on the lives of one (American?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>At one end of the Eighties Warren Beatty creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>An excellent movie about two cops loving the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       pos  Since Educating Rita, Julie Walters has been o...\n",
       "1       pos  This is one of the best movies out there and t...\n",
       "2       pos  Dumland focuses on the lives of one (American?...\n",
       "3       pos  At one end of the Eighties Warren Beatty creat...\n",
       "4       pos  An excellent movie about two cops loving the s..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>\"Sweeney Todd\" is in my opinion one of a few \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>I know that to include everything in the book,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>The title refers not to a questionable poker h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>How is it possible to like and dislike the sam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0       pos  \"Sweeney Todd\" is in my opinion one of a few \"...\n",
       "1       pos  I know that to include everything in the book,...\n",
       "2       pos  It worked! Director Christian Duguay created a...\n",
       "3       pos  The title refers not to a questionable poker h...\n",
       "4       pos  How is it possible to like and dislike the sam..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = pd.Series(get_embedding(train_ds['text'][0], tokenizer, model))\n",
    "embed.index = 'bert_'+embed.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_feats = list(embed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dumland focuses on the lives of one (American?) family... The father; a violent and obscene person who loves to fart and use profanity and who has no redeeming qualities. The mother; who appears to be a paranoid psychotic, never really says much. The son; an obscure annoying repetitive little fellow. The animation is simple and crude, but does suite the stories and the characters. The episodes were originally only available from the davidlynch.com website, but have now been released on DVD. There are 8 episodes on the DVD and a brief synopsis follows:<br /><br />1- The Neighbor: We meet the next door neighbor, and find out three things about him... he has a really nice shed, he only has one arm and he likes to do naughty things with ducks.<br /><br />2- The Treadmill: We find out that the wife has an affinity for exercise, but the husband doesn\\'t really think it\\'s a good idea. In the end, the exercise treadmill is victorious.<br /><br />3- The Doctor: The father has an unfortunate accident with an exposed live wire... the doctor\\'s examination is quite thorough (if not unconventional) but the diagnosis is \"you are perfectly normal\" (but we knew that).<br /><br />4- A Friend Visits: After an altercation with the new clothes hoist, a friend comes to visit (Believe it or not, he has one! but after we meet him we can understand why), no surprises when he tells us what his hobbies are.<br /><br />5- Get The Stick: We meet another neighbor, he has a stick stuck in his mouth (although we never find out how it got there). Unfortunately, removing the stick from his neighbor\\'s mouth ends up being harder (and more violent) than expected... but he is victorious in the end... Jesus some people can be ungrateful!!!<br /><br />6- My Teeth Are Bleeding: This was my favorite episode... and was also the most mind- numbingly repetitive and annoying (hmm, what does that say about me??). Not sure why the son\\'s teeth started bleeding, but believe me when I say it was minimal to the plot of the story. Which is an oxymoron, as the story had no plot. But did have a funny ending (involving a fly)!!<br /><br />7- Uncle Bob: After meeting Uncle Bob, and Uncle bob\\'s wife, we get a distinct feeling that the Dumbland gene-pool is very shallow. Uncle Bob is a sickly fellow (I shan\\'t elaborate, lest I spoil it for you). Uncle Bob\\'s wife definitely wears the pants in his family... and the father definitely ends up on the wrong side of her ample fist (and spends the rest of their visit cowering in a tree in the back yard).<br /><br />8- Ants: After the home gets infiltrated with ants, and a misbegotten attempt to bug-spray them goes awry... he ends up spraying himself in the face with the bug-spray and starts hallucinating. The ants put on a fabulous song and dance show... he goes berserk trying to kill them, winds up in a full body plaster... and lets just say, the ants get their vengeance in the end.<br /><br />As bad as these stories are, there is something that kept compelling me to watch them. They do give another insight into the mind of one of my favorite directors. David Lynch. Maybe they were an outlet for him, to get rid of some of his violent thoughts?? I did actually laugh out loud at many points within the episodes. Many aspects are absurdly funny!!'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84c20a84d3047588cf1fb69f27faf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for x in embed_feats:\n",
    "    train_ds[x] = None\n",
    "\n",
    "for ridx, row in tqdm(train_ds.iterrows(), total=len(train_ds)):\n",
    "    embed = get_embedding(row['text'], tokenizer, model)\n",
    "    train_ds.loc[ridx, embed_feats] = embed\n",
    "train_ds.to_csv(DATA_DIR+'/imdb_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>bert_4</th>\n",
       "      <th>bert_5</th>\n",
       "      <th>bert_6</th>\n",
       "      <th>bert_7</th>\n",
       "      <th>...</th>\n",
       "      <th>bert_758</th>\n",
       "      <th>bert_759</th>\n",
       "      <th>bert_760</th>\n",
       "      <th>bert_761</th>\n",
       "      <th>bert_762</th>\n",
       "      <th>bert_763</th>\n",
       "      <th>bert_764</th>\n",
       "      <th>bert_765</th>\n",
       "      <th>bert_766</th>\n",
       "      <th>bert_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>Since Educating Rita, Julie Walters has been o...</td>\n",
       "      <td>-0.217232</td>\n",
       "      <td>-0.278537</td>\n",
       "      <td>0.0245923</td>\n",
       "      <td>-0.190077</td>\n",
       "      <td>0.338728</td>\n",
       "      <td>0.198379</td>\n",
       "      <td>0.155497</td>\n",
       "      <td>0.505957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229349</td>\n",
       "      <td>0.110953</td>\n",
       "      <td>-0.0484041</td>\n",
       "      <td>-0.267151</td>\n",
       "      <td>-0.375385</td>\n",
       "      <td>-0.221558</td>\n",
       "      <td>0.410194</td>\n",
       "      <td>-0.0308594</td>\n",
       "      <td>0.250553</td>\n",
       "      <td>0.0608983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is one of the best movies out there and t...</td>\n",
       "      <td>-0.0520091</td>\n",
       "      <td>-0.275612</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.037968</td>\n",
       "      <td>0.363718</td>\n",
       "      <td>0.0504799</td>\n",
       "      <td>0.126078</td>\n",
       "      <td>0.849306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192496</td>\n",
       "      <td>-0.0645858</td>\n",
       "      <td>0.00871947</td>\n",
       "      <td>-0.37895</td>\n",
       "      <td>-0.302224</td>\n",
       "      <td>0.0305593</td>\n",
       "      <td>0.274638</td>\n",
       "      <td>-0.174276</td>\n",
       "      <td>0.252467</td>\n",
       "      <td>-0.049769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>Dumland focuses on the lives of one (American?...</td>\n",
       "      <td>-0.169023</td>\n",
       "      <td>-0.00588888</td>\n",
       "      <td>0.38256</td>\n",
       "      <td>-0.115467</td>\n",
       "      <td>0.296713</td>\n",
       "      <td>0.0632041</td>\n",
       "      <td>0.0517839</td>\n",
       "      <td>0.567073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328033</td>\n",
       "      <td>0.0104621</td>\n",
       "      <td>0.170062</td>\n",
       "      <td>-0.453052</td>\n",
       "      <td>-0.0730496</td>\n",
       "      <td>-0.352005</td>\n",
       "      <td>0.217358</td>\n",
       "      <td>0.124859</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.174639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>At one end of the Eighties Warren Beatty creat...</td>\n",
       "      <td>-0.104024</td>\n",
       "      <td>0.118619</td>\n",
       "      <td>0.313575</td>\n",
       "      <td>0.00533325</td>\n",
       "      <td>0.251248</td>\n",
       "      <td>-0.109587</td>\n",
       "      <td>-0.155153</td>\n",
       "      <td>0.548621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314867</td>\n",
       "      <td>0.0480268</td>\n",
       "      <td>0.189538</td>\n",
       "      <td>-0.187595</td>\n",
       "      <td>-0.0315852</td>\n",
       "      <td>-0.204041</td>\n",
       "      <td>0.114504</td>\n",
       "      <td>-0.13663</td>\n",
       "      <td>0.32883</td>\n",
       "      <td>0.0359153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>An excellent movie about two cops loving the s...</td>\n",
       "      <td>-0.290859</td>\n",
       "      <td>-0.307483</td>\n",
       "      <td>0.35993</td>\n",
       "      <td>0.252686</td>\n",
       "      <td>0.42174</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.123191</td>\n",
       "      <td>0.444648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00187467</td>\n",
       "      <td>-0.169472</td>\n",
       "      <td>0.0661618</td>\n",
       "      <td>-0.316122</td>\n",
       "      <td>-0.594344</td>\n",
       "      <td>0.0895601</td>\n",
       "      <td>0.26017</td>\n",
       "      <td>-0.23363</td>\n",
       "      <td>0.373538</td>\n",
       "      <td>0.0267218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text     bert_0  \\\n",
       "0       pos  Since Educating Rita, Julie Walters has been o...  -0.217232   \n",
       "1       pos  This is one of the best movies out there and t... -0.0520091   \n",
       "2       pos  Dumland focuses on the lives of one (American?...  -0.169023   \n",
       "3       pos  At one end of the Eighties Warren Beatty creat...  -0.104024   \n",
       "4       pos  An excellent movie about two cops loving the s...  -0.290859   \n",
       "\n",
       "       bert_1     bert_2      bert_3    bert_4     bert_5     bert_6  \\\n",
       "0   -0.278537  0.0245923   -0.190077  0.338728   0.198379   0.155497   \n",
       "1   -0.275612   0.290984    0.037968  0.363718  0.0504799   0.126078   \n",
       "2 -0.00588888    0.38256   -0.115467  0.296713  0.0632041  0.0517839   \n",
       "3    0.118619   0.313575  0.00533325  0.251248  -0.109587  -0.155153   \n",
       "4   -0.307483    0.35993    0.252686   0.42174   0.044342   0.123191   \n",
       "\n",
       "     bert_7    ...        bert_758   bert_759    bert_760  bert_761  \\\n",
       "0  0.505957    ...       -0.229349   0.110953  -0.0484041 -0.267151   \n",
       "1  0.849306    ...       -0.192496 -0.0645858  0.00871947  -0.37895   \n",
       "2  0.567073    ...       -0.328033  0.0104621    0.170062 -0.453052   \n",
       "3  0.548621    ...       -0.314867  0.0480268    0.189538 -0.187595   \n",
       "4  0.444648    ...      0.00187467  -0.169472   0.0661618 -0.316122   \n",
       "\n",
       "    bert_762   bert_763  bert_764   bert_765  bert_766   bert_767  \n",
       "0  -0.375385  -0.221558  0.410194 -0.0308594  0.250553  0.0608983  \n",
       "1  -0.302224  0.0305593  0.274638  -0.174276  0.252467  -0.049769  \n",
       "2 -0.0730496  -0.352005  0.217358   0.124859    0.4517   0.174639  \n",
       "3 -0.0315852  -0.204041  0.114504   -0.13663   0.32883  0.0359153  \n",
       "4  -0.594344  0.0895601   0.26017   -0.23363  0.373538  0.0267218  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ccd713b7744fcfafc1922d0d235185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-cd0324c67cbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mridx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mridx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_feats\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/imdb_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-50d00aa5199d>\u001b[0m in \u001b[0;36mget_embedding\u001b[0;34m(text, tokenizer, model)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Predict hidden states features for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in embed_feats:\n",
    "    test_ds[x] = None\n",
    "\n",
    "for ridx, row in tqdm(test_ds.iterrows(), total=len(test_ds)):\n",
    "    embed = get_embedding(row['text'], tokenizer, model)\n",
    "    test_ds.loc[ridx, embed_feats] = embed\n",
    "test_ds.to_csv(DATA_DIR+'/imdb_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = pd.Series(get_embedding(train_ds['text'][0], tokenizer, model))\n",
    "embed.index = 'bert_'+embed.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.69022515e-01, -5.88888302e-03,  3.82559597e-01, -1.15467012e-01,\n",
       "        2.96713322e-01,  6.32041320e-02,  5.17838597e-02,  5.67072988e-01,\n",
       "       -6.85264319e-02, -1.18583992e-01,  2.23138630e-02, -2.05014825e-01,\n",
       "       -1.63424253e-01,  2.40052760e-01, -1.35879755e-01,  7.12993860e-01,\n",
       "        5.95821083e-01,  8.21804404e-02, -6.92593008e-02,  4.16816294e-01,\n",
       "        8.11818838e-01, -3.45929228e-02, -5.39838821e-02,  4.33455586e-01,\n",
       "        5.90316474e-01,  2.10616767e-01,  1.14611246e-01, -2.10119352e-01,\n",
       "       -3.83716077e-01,  6.31121397e-02,  5.17452002e-01, -3.35183918e-01,\n",
       "        1.87211305e-01, -2.17308223e-01, -9.12466639e-05, -2.35488698e-01,\n",
       "        3.08433846e-02, -2.47839261e-02, -4.46884632e-02,  2.14244984e-02,\n",
       "       -3.74544680e-01, -2.28441000e-01, -9.32470784e-02, -2.55511720e-02,\n",
       "       -8.78452361e-02, -3.93940955e-01,  7.29438901e-01, -2.64874101e-02,\n",
       "       -1.98453460e-02, -5.24623990e-02, -3.79911602e-01,  3.33532274e-01,\n",
       "       -2.74176951e-02,  2.03597873e-01,  5.19160509e-01,  1.66842431e-01,\n",
       "       -2.14507341e-01, -3.40154707e-01, -4.14533347e-01, -4.37128663e-01,\n",
       "        2.18955442e-01, -2.99887687e-01,  3.10932159e-01, -4.21577722e-01,\n",
       "        1.55961275e-01, -4.18512011e-03, -2.05062982e-02,  3.35736096e-01,\n",
       "       -5.19595087e-01,  9.99096408e-02, -1.40799299e-01, -2.64131188e-01,\n",
       "       -1.32434100e-01, -3.07353940e-02, -1.22777916e-01,  1.82345852e-01,\n",
       "       -1.40372634e-01,  1.70326158e-01,  9.40615237e-02,  2.39831522e-01,\n",
       "       -1.36395961e-01,  1.52394727e-01, -7.19374120e-02,  3.83551091e-01,\n",
       "        1.57309517e-01, -2.31953055e-01,  2.21403092e-01,  4.32161838e-01,\n",
       "       -4.80818897e-01,  2.87115812e-01,  1.09037131e-01, -3.24120969e-01,\n",
       "        2.61836909e-02, -2.22602352e-01,  2.33548462e-01, -1.02177858e-01,\n",
       "        2.38147557e-01, -7.98170641e-02, -3.34985435e-01, -8.05923045e-02,\n",
       "       -1.67994335e-01, -2.24087790e-01,  2.44756773e-01,  4.06747907e-02,\n",
       "       -8.05785805e-02, -4.39106673e-02,  3.13985944e-01,  2.69252479e-01,\n",
       "       -1.43678069e-01,  4.43598449e-01,  3.55502456e-01, -2.48308241e-01,\n",
       "       -1.80730950e-02, -4.49206233e-01,  2.79267281e-01,  4.32060882e-02,\n",
       "        2.19746247e-01,  1.62053145e-02, -2.37070229e-02,  3.20346713e-01,\n",
       "        3.27768445e-01, -3.14717144e-01,  1.89636588e-01,  4.32067901e-01,\n",
       "        6.41309768e-02, -5.75982258e-02, -3.19051981e-01,  7.11585581e-02,\n",
       "       -1.30311176e-01, -3.00399095e-01,  4.19915438e-01,  1.65850088e-01,\n",
       "        2.06049606e-01, -1.89875573e-01, -2.46094406e-01, -4.14058343e-02,\n",
       "       -2.96341687e-01, -3.23186159e-01, -2.03470647e-01,  2.69642472e-01,\n",
       "        1.60092548e-01, -6.13755211e-02,  2.80494571e-01,  3.39691848e-01,\n",
       "       -6.77189371e-03,  1.84578180e-01, -1.23409629e-02, -2.51597136e-01,\n",
       "        1.73218429e-01,  1.22039035e-01, -1.03459693e-02,  3.02794695e-01,\n",
       "       -3.96942981e-02, -4.10418510e-01,  4.09999266e-02, -8.47394299e-03,\n",
       "       -1.87356755e-01,  1.73141450e-01, -1.02619804e-01, -1.14458166e-01,\n",
       "        5.88993728e-01, -2.27229446e-02, -9.72512066e-02,  2.71901846e-01,\n",
       "        3.69472355e-01,  6.17155135e-02,  1.52578160e-01,  4.57401156e-01,\n",
       "       -2.97944367e-01, -6.41278848e-02, -1.21668547e-01, -1.71366870e-01,\n",
       "        8.28296363e-01,  9.76108015e-02,  3.18441182e-01,  1.74537003e-01,\n",
       "        3.62221867e-01, -4.46206443e-02,  2.89827585e-01, -8.32169577e-02,\n",
       "       -5.29213667e-01,  5.65270841e-01, -2.85679251e-01, -7.87575264e-03,\n",
       "        2.92921215e-01, -1.70704842e-01,  3.59466225e-01,  2.90546548e-02,\n",
       "        3.42579722e-01, -7.41683468e-02, -3.84973884e-01, -2.58774310e-01,\n",
       "       -4.95292842e-01, -8.07798803e-02,  1.58311874e-01, -3.54474746e-02,\n",
       "       -1.91956520e-01,  6.36600927e-02, -3.43218654e-01, -3.49229157e-01,\n",
       "        3.22291926e-02,  2.24874374e-02,  5.12693226e-01,  4.27749336e-01,\n",
       "        1.63849980e-01, -4.16731030e-01,  4.88706045e-02, -1.29346713e-01,\n",
       "       -2.97048446e-02, -1.21238425e-01, -2.58131981e-01,  6.80400804e-02,\n",
       "        1.09055787e-01,  1.42465502e-01, -1.53079376e-01, -1.49310768e-01,\n",
       "        1.31099555e-03, -3.99221063e-01,  2.17076078e-01, -1.63113289e-02,\n",
       "       -2.51880020e-01,  2.58207649e-01, -4.21022773e-01,  3.22113931e-01,\n",
       "        5.37529103e-02,  8.28173935e-01,  2.23462939e-01, -6.92351758e-01,\n",
       "        3.90334308e-01,  3.60292941e-01, -1.09639466e-01, -1.91718221e-01,\n",
       "        5.11222363e-01, -1.80095449e-01, -1.23166479e-01, -1.01736970e-01,\n",
       "       -2.10062131e-01, -2.40653709e-01,  1.63253829e-01, -5.06121635e-01,\n",
       "       -2.84829676e-01,  4.32140976e-01,  3.74413818e-01,  2.48646215e-02,\n",
       "       -1.12602264e-01,  1.08059473e-01,  5.42354472e-02,  6.71237260e-02,\n",
       "       -1.43188223e-01, -2.64916211e-01, -3.33990693e-01, -8.75151232e-02,\n",
       "        6.24300260e-03, -3.37953180e-01, -3.55488472e-02, -2.01993197e-01,\n",
       "       -2.73586661e-01, -4.22049671e-01, -2.21267552e-03,  4.68465723e-02,\n",
       "       -5.10832332e-02, -4.97476291e-03, -4.22680788e-02, -2.04645321e-01,\n",
       "       -3.09478551e-01, -2.59119242e-01,  2.09144019e-02,  3.38279009e-01,\n",
       "        1.10147148e-01,  2.79487699e-01, -5.59155969e-03, -1.36082828e-01,\n",
       "       -6.03988767e-03,  6.26311779e-01, -1.78765073e-01, -5.28175645e-02,\n",
       "        3.54869783e-01,  1.36967316e-01,  2.16646492e-01,  6.60882704e-03,\n",
       "       -2.58283988e-02,  4.28472310e-01, -3.19678992e-01, -2.05198884e-01,\n",
       "       -3.55111390e-01, -2.39377871e-01,  3.84056300e-01,  1.07824849e-02,\n",
       "       -4.29849386e-01,  5.25553860e-02,  4.91873696e-02,  1.93792641e-01,\n",
       "       -1.88108146e-01, -3.43146354e-01,  4.01772857e-02,  2.08842486e-01,\n",
       "        1.44428179e-01,  3.34946036e-01,  5.11772156e-01,  9.97930113e-03,\n",
       "       -1.43133074e-01, -5.09734452e-01,  5.87496534e-02,  1.25963733e-01,\n",
       "        1.50124161e-02,  2.36422881e-01,  1.89988524e-01, -4.36298132e-01,\n",
       "       -3.63531947e+00,  2.04224601e-01,  4.12836015e-01, -1.51716948e-01,\n",
       "        2.39589214e-01,  1.13045081e-01, -1.22879803e-01, -3.25259119e-01,\n",
       "       -2.91996956e-01,  2.05854818e-01,  1.60792381e-01, -3.26709509e-01,\n",
       "        2.36078411e-01,  1.27494797e-01,  4.19192582e-01, -6.38654232e-01,\n",
       "        1.52689731e-02, -2.57562339e-01, -1.04156911e-01,  5.24150789e-01,\n",
       "       -2.21363455e-01, -3.15299004e-01,  2.47884929e-01, -1.29055053e-01,\n",
       "        3.41154605e-01,  8.89438868e-01, -3.53656739e-01, -3.50140005e-01,\n",
       "       -1.61495596e-01, -2.23657191e-01,  3.24277282e-01, -4.51833904e-01,\n",
       "       -1.04610249e-01, -2.01245129e-01,  2.33548537e-01,  3.63378853e-01,\n",
       "        1.36001110e-01, -4.77632344e-01, -2.24572375e-01, -3.55555028e-01,\n",
       "       -6.38904423e-03, -8.07080209e-01, -2.77854264e-01, -3.04963201e-01,\n",
       "        6.14105344e-01,  1.97964814e-02, -4.12114076e-02, -1.79447621e-01,\n",
       "        3.71556103e-01,  2.12830991e-01,  1.91890225e-01,  8.46448541e-02,\n",
       "       -3.27010512e-01, -6.39713332e-02,  2.48869155e-02, -1.28880190e-02,\n",
       "        3.38794261e-01,  2.49686867e-01, -2.81376600e-01, -3.57495308e-01,\n",
       "       -1.80158183e-01, -3.80527303e-02, -6.32538915e-01, -7.65185505e-02,\n",
       "       -1.90805927e-01, -4.33714986e-01, -3.17069739e-01,  3.39362323e-01,\n",
       "       -9.81046334e-02, -6.83197156e-02, -1.85430020e-01,  3.20245326e-01,\n",
       "       -2.79977053e-01,  2.60300547e-01,  1.40779585e-01, -4.09602284e-01,\n",
       "        5.56974523e-02, -3.40348154e-01,  1.53564900e-01, -1.74060255e-01,\n",
       "       -3.97694230e-01, -6.04612231e-01, -2.07667813e-01, -7.21968561e-02,\n",
       "       -2.24045739e-01, -2.19513461e-01,  8.23431909e-02, -4.77544963e-02,\n",
       "       -4.29312259e-01, -2.90954053e-01,  1.46230787e-01, -1.25308305e-01,\n",
       "       -7.14397058e-02,  4.13398631e-02,  2.99117804e-01,  4.07015420e-02,\n",
       "        2.69231852e-02,  6.37970418e-02,  8.10566843e-02, -2.54029840e-01,\n",
       "        1.77972630e-01,  2.33489394e-01,  3.75563622e-01, -1.03906408e-01,\n",
       "        2.20899601e-02, -5.25780506e-02, -3.84768248e-01, -8.58477503e-02,\n",
       "        3.22629027e-02, -7.18741193e-02,  1.70856833e-01, -5.11217654e-01,\n",
       "        3.72824579e-01, -2.82325387e-01,  2.01902330e-01, -1.76839605e-01,\n",
       "        1.55013651e-01,  4.25222367e-01,  5.19208722e-02, -3.90773058e-01,\n",
       "       -3.49308968e-01,  5.54583192e-01, -4.46054786e-01,  1.07139349e-01,\n",
       "       -5.73419072e-02,  2.93849111e-01, -1.39058694e-01,  1.63353533e-01,\n",
       "        2.31620997e-01, -9.29668546e-02, -3.87924105e-01, -2.66594797e-01,\n",
       "        1.35223731e-01,  3.22409868e-01,  1.34358138e-01, -1.75233245e-01,\n",
       "        3.44649516e-02, -7.82958984e-01,  6.14643060e-02,  4.56038624e-01,\n",
       "       -1.22211128e-01,  1.31342083e-01, -1.98179290e-01, -4.97121885e-02,\n",
       "       -1.36031359e-01,  4.11292940e-01,  1.21866778e-01,  1.58609346e-01,\n",
       "       -9.56713632e-02, -6.69577792e-02, -3.86917025e-01, -1.86597258e-01,\n",
       "       -1.70433715e-01, -4.29541558e-01,  7.44794309e-02,  1.33677438e-01,\n",
       "       -3.38495940e-01,  1.06894761e-01,  1.77785661e-02, -3.25672150e-01,\n",
       "       -6.59358203e-02, -9.74203423e-02,  1.36018485e-01,  3.03504258e-01,\n",
       "       -2.71306068e-01,  3.90396267e-01, -1.78278908e-01, -1.56207070e-01,\n",
       "       -6.57831654e-02,  1.76369801e-01, -8.93121287e-02, -7.41362348e-02,\n",
       "       -1.42010093e-01,  3.32511336e-01,  1.66163966e-01,  3.94397020e-01,\n",
       "       -6.31619766e-02, -3.23557794e-01, -2.61636645e-01,  4.86939371e-01,\n",
       "        3.07032075e-02, -3.47643763e-01, -1.36921078e-01, -4.58804488e-01,\n",
       "        2.12029099e-01, -2.11187914e-01,  3.71459246e-01, -1.46132976e-01,\n",
       "        1.17625184e-01,  1.99328944e-01,  4.10055667e-02,  8.17985609e-02,\n",
       "        1.29452899e-01,  2.64002055e-01, -1.17862828e-01, -9.61905792e-02,\n",
       "        3.00090879e-01, -1.74303472e-01,  9.88402814e-02,  6.86884299e-02,\n",
       "       -3.83387133e-02, -3.03994715e-01, -1.41727075e-01,  4.79682386e-02,\n",
       "        1.28159419e-01, -3.43900591e-01,  1.33804560e-01,  2.88133509e-03,\n",
       "       -7.33418763e-02,  2.15562686e-01, -5.41832387e-01, -1.09243594e-01,\n",
       "       -3.30529898e-01, -1.38047799e-01, -1.57255933e-01, -5.41027546e-01,\n",
       "       -2.74758879e-03, -1.12158030e-01, -2.89921343e-01, -5.23140654e-03,\n",
       "       -4.24729347e-01, -2.77700841e-01,  2.12887898e-01, -5.94404563e-02,\n",
       "       -4.42816406e-01, -2.03816265e-01,  3.90315317e-02, -2.63935357e-01,\n",
       "       -3.43833980e-03, -4.76604223e-01,  4.20306623e-01, -4.17533606e-01,\n",
       "       -1.23659045e-01,  1.65584639e-01, -7.40012005e-02,  3.37869644e-01,\n",
       "       -2.92541623e-01, -8.15485597e-01, -3.38899881e-01, -1.20752439e-01,\n",
       "        3.43221366e-01,  8.95160288e-02, -1.42899320e-01, -2.50259250e-01,\n",
       "        3.31787109e-01, -1.48391977e-01, -1.58729032e-01, -4.97914962e-02,\n",
       "       -3.58283296e-02,  5.13388813e-01, -7.67355412e-02, -3.66459088e-03,\n",
       "       -3.15505527e-02, -1.08982742e-01, -3.68741229e-02, -5.76867759e-01,\n",
       "       -5.96038997e-01, -1.47834318e-02, -2.16149703e-01, -1.69736922e-01,\n",
       "       -1.39966801e-01, -1.93697184e-01, -1.55852422e-01,  1.25457689e-01,\n",
       "        3.66191328e-01, -1.03176467e-01, -2.05092907e-01,  3.12208772e-01,\n",
       "       -6.68689888e-03, -3.31674159e-01, -1.48015888e-02, -4.55886662e-01,\n",
       "       -4.41764705e-02, -1.88524231e-01,  1.87647685e-01, -4.12538312e-02,\n",
       "       -1.30250715e-02, -5.35315633e-01,  1.07906200e-01, -4.08250183e-01,\n",
       "       -1.95741713e-01,  5.84697723e-02, -1.31637111e-01, -3.33207175e-02,\n",
       "        1.46420047e-01, -3.99152905e-01,  2.65072227e-01,  3.60900789e-01,\n",
       "        3.55266668e-02, -9.66579467e-02,  1.06865853e-01, -1.96119156e-02,\n",
       "       -1.24442212e-01, -9.32256728e-02, -2.99934149e-01,  6.23291172e-02,\n",
       "        5.32669902e-01,  1.93158135e-01,  1.84957862e-01, -1.46057144e-01,\n",
       "        9.25530270e-02, -3.95023286e-01,  4.30143297e-01,  6.97310641e-02,\n",
       "       -2.13350788e-01,  3.40520442e-01,  3.10309857e-01, -4.34240580e-01,\n",
       "       -3.64273190e-01,  4.24706131e-01,  1.16886042e-01, -3.16150784e-01,\n",
       "        2.92659760e-01,  3.06039453e-01, -1.58904657e-01, -4.50918674e-01,\n",
       "       -5.21106422e-02, -1.72875375e-01, -4.61854376e-02,  1.77153945e-01,\n",
       "        3.27907085e-01,  1.37389287e-01,  5.22251844e-01,  7.98489377e-02,\n",
       "        7.84189552e-02,  2.63749063e-01,  3.43577601e-02,  5.35155348e-02,\n",
       "       -6.87808096e-02,  1.52488828e-01, -7.72313550e-02,  3.30759943e-01,\n",
       "       -1.57873720e-01,  4.17962730e-01, -3.16015899e-01, -1.31856859e-01,\n",
       "       -5.33600971e-02,  1.47173554e-01,  2.62920260e-01, -1.08067527e-01,\n",
       "       -8.56807455e-02,  5.37970802e-03,  2.99452990e-01,  4.45036739e-01,\n",
       "        2.16291368e-01,  2.01692685e-01,  3.91538471e-01, -3.78117174e-01,\n",
       "        5.63557804e-01,  5.42815685e-01,  1.73563540e-01,  3.11510742e-01,\n",
       "        1.33572266e-01, -3.44068944e-01,  1.79109454e-01,  1.40156746e-01,\n",
       "        4.51021433e-01,  9.65279043e-02, -8.03351030e-03,  7.07707107e-01,\n",
       "        3.29926044e-01,  1.18321709e-01,  3.30939233e-01, -4.42310125e-01,\n",
       "       -1.62327468e-01,  2.59714127e-01,  1.62967756e-01, -2.35658988e-01,\n",
       "        1.47805244e-01,  8.81073177e-02,  1.05157524e-01,  7.04654306e-02,\n",
       "       -3.03026527e-01, -3.67412448e-01, -4.33086634e-01,  4.42873001e-01,\n",
       "        6.02148995e-02,  1.07320361e-01, -1.40406474e-01, -9.63753536e-02,\n",
       "       -2.23047107e-01, -2.98480421e-01, -3.55095536e-01, -2.24553645e-02,\n",
       "       -6.64635524e-02, -3.38757962e-01, -9.48531479e-02, -2.44840905e-01,\n",
       "       -3.01945955e-01, -9.88583267e-02,  8.91240537e-02, -4.17559952e-01,\n",
       "       -1.27550200e-01, -1.73118431e-02,  1.84260886e-02, -5.54450870e-01,\n",
       "        4.01077420e-01,  2.51672447e-01,  7.27911413e-01, -8.42917711e-02,\n",
       "       -2.66930699e-01,  1.63411036e-01,  8.85814279e-02,  8.56700093e-02,\n",
       "        1.80169828e-02, -1.74264386e-01,  4.57293361e-01,  5.17927468e-01,\n",
       "       -3.54067713e-01,  1.16358526e-01,  1.74277164e-02, -9.26296189e-02,\n",
       "       -5.23525417e-01,  1.99624807e-01, -3.22696060e-01, -7.21823201e-02,\n",
       "       -3.07657048e-02,  2.10386559e-01, -4.50621732e-02, -2.02830192e-02,\n",
       "       -8.87314454e-02, -5.21439850e-01, -8.08000714e-02, -8.28604549e-02,\n",
       "       -2.45671868e-01,  3.09989214e-01,  1.61410064e-01,  4.12437230e-01,\n",
       "       -4.18949276e-01,  7.22484142e-02, -1.90185651e-01,  2.22175106e-01,\n",
       "        3.14185619e-02, -2.42925845e-02, -2.93321580e-01, -4.15249050e-01,\n",
       "        6.40721023e-02,  2.90087014e-01, -2.32480779e-01,  4.32011902e-01,\n",
       "        1.26466110e-01,  4.04516488e-01, -1.20348983e-01, -2.72847712e-01,\n",
       "        1.07721634e-01,  2.76379973e-01, -2.08014444e-01, -1.85933545e-01,\n",
       "       -2.32782051e-01, -1.16644509e-01, -3.28033209e-01,  1.04621165e-02,\n",
       "        1.70061678e-01, -4.53052104e-01, -7.30495900e-02, -3.52004647e-01,\n",
       "        2.17357919e-01,  1.24859475e-01,  4.51699853e-01,  1.74639151e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(row['text'], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in embed.index:\n",
    "    train_ds[x] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds.loc[0, embed.index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bert_0     -0.217232\n",
       "bert_1     -0.278537\n",
       "bert_2      0.024592\n",
       "bert_3     -0.190077\n",
       "bert_4      0.338728\n",
       "bert_5      0.198379\n",
       "bert_6      0.155497\n",
       "bert_7      0.505957\n",
       "bert_8      0.094868\n",
       "bert_9     -0.145420\n",
       "bert_10     0.101992\n",
       "bert_11     0.135202\n",
       "bert_12     0.349203\n",
       "bert_13     0.094512\n",
       "bert_14    -0.153228\n",
       "bert_15     0.825148\n",
       "bert_16     0.834473\n",
       "bert_17    -0.019554\n",
       "bert_18    -0.101472\n",
       "bert_19     0.102215\n",
       "bert_20     0.311074\n",
       "bert_21     0.015806\n",
       "bert_22    -0.173801\n",
       "bert_23     0.558773\n",
       "bert_24     0.309150\n",
       "bert_25     0.108638\n",
       "bert_26    -0.004143\n",
       "bert_27     0.030743\n",
       "bert_28    -0.149277\n",
       "bert_29     0.028250\n",
       "              ...   \n",
       "bert_738    0.116874\n",
       "bert_739    0.443467\n",
       "bert_740   -0.137052\n",
       "bert_741    0.096892\n",
       "bert_742   -0.100825\n",
       "bert_743   -0.437084\n",
       "bert_744   -0.081658\n",
       "bert_745   -0.191343\n",
       "bert_746   -0.475989\n",
       "bert_747   -0.102189\n",
       "bert_748   -0.133091\n",
       "bert_749    0.111284\n",
       "bert_750   -0.026696\n",
       "bert_751   -0.169668\n",
       "bert_752    0.334489\n",
       "bert_753   -0.168952\n",
       "bert_754   -0.336284\n",
       "bert_755    0.074298\n",
       "bert_756    0.318154\n",
       "bert_757   -0.090660\n",
       "bert_758   -0.229349\n",
       "bert_759    0.110953\n",
       "bert_760   -0.048404\n",
       "bert_761   -0.267151\n",
       "bert_762   -0.375385\n",
       "bert_763   -0.221558\n",
       "bert_764    0.410194\n",
       "bert_765   -0.030859\n",
       "bert_766    0.250553\n",
       "bert_767    0.060898\n",
       "Length: 768, dtype: float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
